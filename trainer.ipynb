{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import DEBUG, INFO, FileHandler, Formatter, Logger, StreamHandler, getLogger\n",
    "from pathlib import Path\n",
    "\n",
    "_LOGGIN_DIR = Path().parent / \"logs\"\n",
    "\n",
    "if not _LOGGIN_DIR.exists():\n",
    "    _LOGGIN_DIR.mkdir()\n",
    "\n",
    "\n",
    "def create_logger(name: str) -> Logger:\n",
    "    logger = getLogger(name)\n",
    "    logger.setLevel(DEBUG)\n",
    "    stream_handler = StreamHandler()\n",
    "    file_handler = FileHandler(_LOGGIN_DIR / f\"{name}.log\")\n",
    "    formatter = Formatter(fmt=\"%(asctime)s.%(msecs)03d %(levelname)s: %(message)s\", datefmt=\"%Y-%m-%d,%H:%M:%S\")\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setLevel(INFO)\n",
    "    file_handler.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from typing import Optional\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "_DATASETS_DIR = Path().parent / \"datasets\"\n",
    "\n",
    "if not _DATASETS_DIR.exists():\n",
    "    _DATASETS_DIR.mkdir()\n",
    "\n",
    "logger = create_logger(__name__)\n",
    "\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b: int = 1, bsize: int = 1, tsize: int = None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def load_dataset(name: str, url: str, hash: Optional[str] = None) -> None:\n",
    "    directory_name = _DATASETS_DIR / name\n",
    "    archive_name = directory_name.with_suffix(\".zip\")\n",
    "    if not archive_name.exists():\n",
    "        logger.info(f\"Downloading dataset '{url}' into {archive_name}...\")\n",
    "        with DownloadProgressBar(unit=\"B\", unit_scale=True, miniters=1, desc=name) as t:\n",
    "            urlretrieve(url, archive_name, t.update_to)\n",
    "    else:\n",
    "        logger.debug(f\"Dataset '{url}' is found in {archive_name}!\")\n",
    "    if hash is not None:\n",
    "        logger.debug(f\"Verifying dataset {name} archive {archive_name} SHA256 checksum...\")\n",
    "        if sha256(archive_name.read_bytes()).hexdigest() == hash:\n",
    "            logger.info(f\"Dataset {name} SHA256 verification successful!\")\n",
    "        else:\n",
    "            raise ValueError(f\"Error verifying dataset {name} archive {archive_name} SHA256 checksum!\")\n",
    "    if directory_name.is_dir():\n",
    "        logger.debug(f\"Removing previous dataset {name} directory...\")\n",
    "        rmtree(directory_name)\n",
    "    with ZipFile(archive_name, \"r\") as zipfile:\n",
    "        logger.debug(f\"Unpacking dataset {name} into {_DATASETS_DIR}...\")\n",
    "        zipfile.extractall(directory_name)\n",
    "    logger.info(f\"Dataset {name} available in {directory_name}!\")\n",
    "\n",
    "\n",
    "def verify_dataset(name: str) -> None:\n",
    "    directory_name = _DATASETS_DIR / name\n",
    "    if directory_name.is_dir():\n",
    "        logger.info(f\"Dataset {name} found in {directory_name}!\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Dataset {name} does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raXZgluvhdUQ",
    "outputId": "0ab6fb00-2dd7-448c-959f-6c5420af6031"
   },
   "outputs": [],
   "source": [
    "load_dataset(\n",
    "    \"allergen30\",\n",
    "    \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/9ygs9vhnpw-1.zip\",\n",
    "    \"ab6e19d32f7490988ca77d600fc6f3df2e8648365c4c92ced8c1b462c01d9d9f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beqgkS8ZhdUW",
    "outputId": "c3f497eb-df58-4c4a-b949-3928ecb0a8f3"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "YOLO_VERSION = \"yolo11n.pt\"\n",
    "\n",
    "\n",
    "model = YOLO(YOLO_VERSION)\n",
    "\n",
    "print(\"YOLO network parameters:\")\n",
    "for k, v in model.named_parameters():\n",
    "  print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeS8GRuIhdUX",
    "outputId": "667a1dca-6b75-4ab0-fcde-8941b0302312"
   },
   "outputs": [],
   "source": [
    "FREEZE_LAYERS = 10\n",
    "EPOCHS_NUMBER = 15\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 416\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "model.train(\n",
    "    data=\"datasets/allergen30.yaml\",\n",
    "    epochs=EPOCHS_NUMBER,\n",
    "    batch=BATCH_SIZE,\n",
    "    freeze=FREEZE_LAYERS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    lr0=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dpj7GF7MhdUY",
    "outputId": "b756fdaa-16cc-45bc-e3d7-c967f7584cb3"
   },
   "outputs": [],
   "source": [
    "EPOCHS_NUMBER = 7\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 416\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "\n",
    "model.train(\n",
    "    data=\"datasets/allergen30.yaml\",\n",
    "    epochs=EPOCHS_NUMBER,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    lr0=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfbaW6gbhdUZ",
    "outputId": "36e0a24f-93dc-4de3-9f2b-361fbdaee896"
   },
   "outputs": [],
   "source": [
    "results = model.predict(source=\"datasets/allergen30/Allergen30/test/images\", show_labels=True, conf=0.25)\n",
    "print(\"Test set image predictions:\")\n",
    "for r in results:\n",
    "    print(r.boxes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-sWZcVehdUa"
   },
   "outputs": [],
   "source": [
    "model.save(\"find_allergens.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "imagine-food-lMcR2JK_-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
